## iOS面试题难点集锦（二）---参考答案

引言：通过上篇文章[iOS面试题难点集锦（二）](https://github.com/LiuFuBo/iOSInterviewQuestions/blob/master/iOS面试题难点集锦/iOS面试题难点集锦（二）.md)，我们了解了一些散碎的iOS知识点，接下来的篇幅我们会着重讲解一些体系内文章。

# 索引

1. [HTTP工作原理图](#HTTP工作原理图 ) 
2. [HTTP/0.9版本篇](#HTTP/0.9版本篇 )
3. [HTTP/1.0版本篇](#HTTP/1.0版本篇 )
4. [HTTP/1.1版本篇](#HTTP/1.1版本篇 )
5. [HTTP/2.0版本篇](#HTTP/2.0版本篇 )
6. [HTTPS版本篇](#HTTPS版本篇 )
7. [SSL/TLS协议介绍](#SSL/TLS协议介绍 )




### HTTP发展历程？

HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写，是用于从万维网（www.world wide web）服务器传输超文本到本地浏览器的传输协议。HTTP是基于TCP/IP的应用层协议。不涉及到数据包(packet)传输，主要规定了客户端和服务器之间的通信格式，默认使用80端口。  



#### HTTP工作原理图  

![](http://brandonliu.pub/icon_blog_wanweiwang_http.jpg)  



#### HTTP/0.9版本篇  



#### 要点  

* 客户端向服务器请求网页，服务器只能回应HTML格式字符串，不能回应别的格式。  
* 只有GET请求方式。  
* 服务器发送完毕，就关闭TCP连接。  
* 任何格式内容都可以发送—(包括文字、图像、视频、二进制文件)。  


#### 缺点  

* 每个TCP连接只能发送一个请求；发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接。  
* TCP连接的新建成本很高，因为需要客户端和服务器三次握手，并且开始时发送速率较慢。  
* 网页加载的外部资源越多，性能就越差。  
* 只有GET这一种请求方式。  


#### HTTP/1.0版本篇  



#### 要点  

* 除了GET请求格式，还引入了POST和HEAD格式，丰富了浏览器与服务器交互方式。  
* HTTP请求和回应格式发生改变，除了数据部分，每次通信都包括头部分，用来描述数据。  
* 新增功能包括：状态码、多字符集支持、多部分发送、权限、缓存、内容编码等。  


```

HTTP/1.0请求的例子：

GET/HTTP/1.0 
USER-AGENT:MOZILLA/5.0(MACINTOSH;INTEL MAC OS X 10_10_5 ) 
ACCEPT:*/*
第一行为请求命令,必须在尾部添加协议版本(HTTP/1.0)
后面为多行头信息，描述客户端情况

```


```

HTTP/1.0回应的例子：
HTTP/1.0 200 OK              /*协议版本+状态码+状态描述*/
CONTENT-TYPE: TEXT/PLAIN   
CONTENT-LENGTH: 137582
EXPIRES: THU, 05 DEC 1997 16:00:00 GMT
LAST-MODIFIED: WED, 5 AUGUST 1996 15:55:28 GMT
SERVER: APACHE 0.84

<HTML>
  <BODY>HELLO WORLD</BODY>
</HTML>
CONTENT-TYPE:字符编码，HTTP 1.0规定 头部必须是ASCII码，后面可以是任何格式，
因此，服务器回应时，CONTENT-TYPE的作用是：告诉客户端，数据是什么格式

```



#### 缺点  

* 每个TCP连接只能发送一个请求；发送数据完毕，连接关闭，如果还要请求其他资源，必须再新建一个连接。  
* TCP新建成功很高，因为需要客户端和服务器三次握手，并且开始时发送速率较慢。（为了解决这个问题，有些浏览器在请求时，用了一个非标准的Connection字段，即：CONNECTION:KEEP-ALIVE）请求服务器不要关闭TCP连接，以便其他请求复用，服务器同样回复这个字段；以实现TCP的复用，直到客户端或服务器主动关闭连接，但这不是标准字段，不同实现的行为可能导致不一致，因此不是根本的解决办法。  
* 网页加载外部资源越多，性能越差。  


#### HTTP/1.1版本篇  



##### 要点  


* 引入持久连接  

```

1.持久连接定义：即TCP连接默认不关闭，可以被多个请求复用，不用声明。
2.引入方式：CONNECTION:KEEP-ALINE
3.关闭连接：客户端和服务器发现对方有单时间没有活动，就可以主动关闭连接。不过，规范的做法是，客户端在最后一个请求时明确要求服务器关闭TCP连接。CONNECTION:CLOSE
4.对于同一个域名，大多数浏览器允许同时建立6个持久连接。

```

* 引入管道机制  


```
1.管道机制：在同一个TCP连接里面，客户端可以同时发送多个请求。（提高HTTP协议的效率）
例：客户端需要请求两个资源，HTTP 1.0是在同一个TCP连接里面，先发送A请求，然后等待服务器做出回应，收到后再发送B请求；管道机制是允许浏览器同时发生A请求和B请求，但是服务器还是按照顺序，先回应A请求，完成后再回应B请求。
2.一个TCP连接可以传送多个回应，势必要有机制区分数据包属于哪个回应；则需要Content-length字段，它的作用就是声明本次回应数据长度。（服务器发送回应之前，必须知道回应数据长度）

```

* 采用分块传输编码  

```
1.使用Content-length字段前提是服务器发送回应之前，必须知道回应数据长度。但对于一些耗时的动态操作，意味着，服务器要等待所有操作完成，才能发送数据，显然效率不高。
2.更好的处理方式是：服务器每产生一块数据，就发送一块，采用"流模式 (stream)"取代"缓存模式（buffer）"，因此，HTTP/1.1版本规定可以不使用Content-length字段，而使用"分块传输编码"，只要请求或回应的头信息有Transfer-Encoding字段，就表明回应的数据将有数量未定的数据块组成，最后是一个大小为0的块，就标识本次回应的数据发送完毕。

```


* 新增 PUT、PATCH、HEAD、OPTIONS、DELECT.客户端的头信息增加HOST字段，用来自定指定服务器的域名。HOST:WWW.EXAMPLE.COM 有了HOST字段，就可以将请求发往同一台服务器的不同网站，为虚拟主机新起打下了基础。  


#### 缺点  


* <font color = #FFFFFF bgcolor=#FFC0CB>HTTP层面队头阻塞: </font>虽然复用TCP连接，但是在同一个TCP连接里面，所有的数据通信都是按照次序进行的。服务器只有处理完一个回应，才能进行下一个回应。 


```
解决方案：
1.减少HTTP请求数。
2.同事多开持久连接。

```

#### HTTP/2.0版本篇  



#### 要点  


* 采用二进制协议  


```
1.HTTP/1.1的头信息是文本(ASCII编码)， 数据体可以是文本（解析非常麻烦），也可以是二进制。
2.HTTP/2.0则是一个彻底的二进制协议，头信息和数据体都是二进制，统称为"帧（frame）:头信息帧、数据帧"。二进制协议有一个好处是可以定义额外的帧，方便解析。

```

* 多路复用（双向，实时的通信）  


```
HTTP/2.0复用TCP连接，在一个连接里，客户端和服务端都可以同时发送多个请求或回应，而不用按照顺序一一对应，这样就避免"队头阻塞"。
例：在一个TCP连接里面，服务器同时受到A请求和B请求，先回应A请求，结果发现处理过程非常耗时，于是就发送A请求已经处理好的部分，接着回应B请求，完成后，才发送B请求剩下的部分。

```

* 数据流  


```
1.HTTP/2.0数据流是不按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此必须要对数据包标记，指出它属于哪个回应。
2.HTTP/2.0将每一个请求或回应的所有数据包，称为一个数据流。每个数据流都有一个独一无二的编号。数据包发送时，都必须标记数据ID，用于区分它数据哪一个数据流；另外规定：客户端发出的数据流，ID一律为奇数，服务器发送的，ID为偶数。
3.数据流发送一半时，客户端和服务器都可以发送信号，取消这个数据流。即HTTP/2.0可以取消某一个请求，同事保证TCP连接还开着，可以被其他请求使用。客户端还可以指定数据流的优先级，优先级越高，服务器就越早回应。

````


* 头信息压缩  


```
1.HTTP/2.0以前的版本协议不带有状态，每次请求都必须附带上所有信息。所以，请求的很多字段都是重复的，比如Cookie和User Agent一模一样，每次请求都必须附带，这很浪费宽带，也影响速度。
2.HTPP/2.0优化了这一点，引入了投信息压缩机制，一方面头信息使用gzip或者compress压缩后再发送，另一方面，客户端和服务端同事维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段，只发送索引号，提高速度。

```

* 服务器推送  


```
1.HTTP/2.0允许服务器未经允许，主动向客户端发送资源。
例：客户端请求一个网页，这个网页里面包含静态资源。正常情况下，客户端必须收到网页后，解析HTML源码，发现有静态资源，再发送静态资源请求；其实服务器可以预期到客户端请求网页后，很可能再请求静态资源，所以主动把这些静态资源随网页一起发送给客户端。

````


#### 缺点   


* <font color = #FFFFFF bgcolor=#FFC0CB>TCP层面发生队头阻塞：</font>将数组分为帧来传输，当一个请求出现了一个数据包丢失，TCP协议会发生阻塞整个TCP连接就会暂停，然后进行数据的重传。这样就造成了队头阻塞。  


#### HTTP3.0篇  

HTTP2.0是2015年推出的，还是比较年轻的，其重要的二进制分帧协议、多路复用、头部压缩、服务端推送等重要优化使HTTP协议真正上了一个新台阶。  
![](http://brandonliu.pub/icon_blog_http2.0_function.png)  
像谷歌这种重要的公司并没有满足于此，而且想继续提升HTTP的性能，花最少的时间和资源获取极致体验。  
那么肯定要问HTTP2.0虽然性能已经不错了，还有什么不足吗？
* 建立连接时间长(本质上是TCP的问题)  
* 队头阻塞问题  
* ......  
熟悉HTTP2.0协议的同学应该知道，这些缺点基本都是由于TCP协议引起的，水能载舟亦能覆舟，其实TCP也很无辜呀！  
![](http://brandonliu.pub/icon_blog_http2.0_three_hand.png)  
在我们眼里，TCP是面向连接、可靠的传输层协议，当前几乎所有重要的协议和应用都是基于TCP来实现的。  
网络环境的改变速度很快，但是TCP协议相对缓慢，正是这种矛盾促使谷歌做出了一个看似出乎意料的决定-基于UDP来开发新一代HTTP协议。  
  
  

谷歌为什么选择UDP  
上文提到，谷歌选择UDP是看似出乎意料的，仔细想一想其实很有道理。  
我们单纯地看看TCP协议的不足和UDP的一些优点：  
* 基于TCP开发的设备和协议非常多，兼容困难  
* TCP协议栈是Linux内部的重要部分，修改和升级成本很大  
* UDP本身是无连接的、没有建链和拆链成本  
* UDP的数据包无队头阻塞问题  
* UDP改造成本小  
从上面的对比可以知道，谷歌要想从TCP上进行改造升级绝非易事，但是UDP虽然没有TCP为了保证可靠连接而引发的问题，但是UDP本身不可靠，又不能直接用。  
![](http://brandonliu.pub/icon_blog_udp_gaizao.jpeg)  
综合而知，谷歌决定在UDP基础上改造一个具备TCP协议优点的新协议也就顺理成章了，这个新协议就是QUIC协议。  


QUIC协议和HTTP3.0  
QUIC其实是Quick UDP Internet Connections的缩写，直译为快速UDP互联网连接。  
* QUIC协议最初由Google的Jim Roskind设计，实施并于2012年部署，在2013年随着实验的扩大而公开宣布，并向IETF进行了描述。  
* QUIC提高了当前正在使用TCP的面向连接的Web应用程序的性能。它在两个端点之间使用用户数据报协议（UDP）建立多个复用连接来实现此目的。  
* QUIC的次要目标包括减少连接和传输延迟，在每个方向进行带宽估计以避免拥塞。它还将拥塞控制算法移动到用户空间，而不是内核空间，此外使用前向纠错（FEC）进行扩展，以在出现错误时进一步提高性能。  
HTTP3.0又称为HTTP Over QUIC，其弃用TCP协议，改为使用基于UDP协议的QUIC协议来实现。  
![](http://brandonliu.pub/icon_blog_upd_quic.jpeg)   


QUIC协议详解  
HTTP3.0既然选择了QUIC协议，也就意味着HTTP3.0基本继承了HTTP2.0的强大功能，并且进一步解决了HTTP2.0存在的一些问题，同时必然引入了新的问题。  
![](http://brandonliu.pub/icon_blog_http2.0_question.png)  
QUIC协议必须要实现HTTP2.0在TCP协议上的重要功能，同时解决遗留问题，我们来看看QUIC是如何实现的。  


队头阻塞问题  
队头阻塞 Head-of-line blocking（缩写为HOL blocking）是计算机网络中是一种性能受限的现象，通俗来说就是：一个数据包影响了一堆数据包，它不来大家都走不了。  
队头阻塞问题可能存在于HTTP层和TCP层，在HTTP1.x时两个层次都存在该问题。  
![](http://brandonliu.pub/icon_blog_duitou_zusai.png)  

HTTP2.0协议的多路复用机制解决了HTTP层的队头阻塞问题，但是在TCP层仍然存在队头阻塞问题。  
TCP协议在收到数据包之后，这部分数据可能是乱序到达的，但是TCP必须将所有数据收集排序整合后给上层使用，如果其中某个包丢失了，就必须等待重传，从而出现某个丢包数据阻塞整个连接的数据使用。  
QUIC协议是基于UDP协议实现的，在一条链接上可以有多个流，流与流之间是互不影响的，当一个流出现丢包影响范围非常小，从而解决队头阻塞问题。  


0RTT 建链  
衡量网络建链的常用指标是RTT Round-Trip Time，也就是数据包一来一回的时间消耗。  
![](http://brandonliu.pub/icon_blog_round_rt.jpeg)  
RTT包括三部分：往返传播时延、网络设备内排队时延、应用程序数据处理时延。  
![](http://brandonliu.pub/icon_blog_Rt_time.jpeg)  
一般来说HTTPS协议要建立完整链接包括:TCP握手和TLS握手，总计需要至少2-3个RTT，普通的HTTP协议也需要至少1个RTT才可以完成握手。  
然而，QUIC协议可以实现在第一个包就可以包含有效的应用数据，从而实现0RTT，但这也是有条件的。
![](http://brandonliu.pub/icon_blog_woshou_liucheng.gif)  
简单来说，基于TCP协议和TLS协议的HTTP2.0在真正发送数据包之前需要花费一些时间来完成握手和加密协商，完成之后才可以真正传输业务数据。  
但是QUIC则第一个数据包就可以发业务数据，从而在连接延时有很大优势，可以节约数百毫秒的时间。  
![](http://brandonliu.pub/icon_blog_quic_jiami_pre.png)  
QUIC的0RTT也是需要条件的，对于第一次交互的客户端和服务端0RTT也是做不到的，毕竟双方完全陌生。  
因此，QUIC协议可以分为首次连接和非首次连接，两种情况进行讨论。  



首次连接和非首次连接  
使用QUIC协议的客户端和服务端要使用1RTT进行密钥交换，使用的交换算法是DH(Diffie-Hellman)迪菲-赫尔曼算法。  
DH算法开辟了密钥交换的新思路，在之前的文章中提到的RSA算法也是基于这种思想实现的，但是DH算法和RSA的密钥交换不完全一样，感兴趣的读者可以看看DH算法的数学原理。  



首次连接  
简单来说一下，首次连接时客户端和服务端的密钥协商和数据传输过程，其中涉及了DH算法的基本过程：  
* 客户端对于首次连接的服务端先发送client hello请求。  
* 服务端生成一个素数p(除了1和他本身，不能被其他数整除)和一个整数g，同时生成一个随机数 (笔误-此处应该是Ks_pri)为私钥，然后计算出公钥 = mod p，服务端将，p，g三个元素打包称为config，后续发送给客户端。  
* 客户端随机生成一个自己的私钥，再从config中读取g和p，计算客户端公钥 = mod p。  
* 客户端使用自己的私钥和服务端发来的config中读取的服务端公钥，生成后续数据加密用的密钥K = mod p。  
* 客户端使用密钥K加密业务数据，并追加自己的公钥，都传递给服务端。  
* 服务端根据自己的私钥和客户端公钥生成客户端加密用的密钥K = mod p。  
* 为了保证数据安全，上述生成的密钥K只会生成使用1次，后续服务端会按照相同的规则生成一套全新的公钥和私钥，并使用这组公私钥生成新的密钥M。  
* 服务端将新公钥和新密钥M加密的数据发给客户端，客户端根据新的服务端公钥和自己原来的私钥计算出本次的密钥M，进行解密。  
* 之后的客户端和服务端数据交互都使用密钥M来完成，密钥K只使用1次。  
![](http://brandonliu.pub/icon_blog_jiami_guocheng.png)  
非首次连接  
前面提到客户端和服务端首次连接时服务端传递了config包，里面包含了服务端公钥和两个随机数，客户端会将config存储下来，后续再连接时可以直接使用，从而跳过这个1RTT，实现0RTT的业务数据交互。  
客户端保存config是有时间期限的，在config失效之后仍然需要进行首次连接时的密钥交换。  


前向安全问题  
通俗来说，前向安全指的是密钥泄漏也不会让之前加密的数据被泄漏，影响的只有当前，对之前的数据无影响。  
前面提到QUIC协议首次连接时先后生成了两个加密密钥，由于config被客户端存储了，如果期间服务端私钥泄漏，那么可以根据K = mod p计算出密钥K。  前面提到QUIC协议首次连接时先后生成了两个加密密钥，由于config被客户端存储了，如果期间服务端私钥泄漏，那么可以根据K = mod p计算出密钥K。  
![](http://brandonliu.pub/icon_blog_xiangqian_jiucuo.png)  
前向纠错  
听这段描述就是做校验的，看看QUIC协议是如何实现的：  
* QUIC每发送一组数据就对这组数据进行异或运算，并将结果作为一个FEC包发送出去，接收方收到这一组数据后根据数据包和FEC包即可进行校验和纠错。  

连接迁移  
网络切换几乎无时无刻不在发生。  
TCP协议使用五元组来表示一条唯一的连接，当我们从4G环境切换到wifi环境时，手机的IP地址就会发生变化，这时必须创建新的TCP连接才能继续传输数据。  
QUIC协议基于UDP实现摒弃了五元组的概念，使用64位的随机数作为连接的ID，并使用该ID表示连接。  
基于QUIC协议之下，我们在日常wifi和4G切换时，或者不同基站之间切换都不会重连，从而提高业务层的体验。  
![](http://brandonliu.pub/icon_blog_jiyu_udp_quic.png)  
QUIC的应用和前景  
通过前面的一些介绍我们看出来QUIC协议虽然是基于UDP来实现的，但是它将TCP的重要功能都进行了实现和优化，否则使用者是不会买账的。  
QUIC协议的核心思想是将TCP协议在内核实现的诸如可靠传输、流量控制、拥塞控制等功能转移到用户态来实现，同时在加密传输方向的尝试也推动了TLS1.3的发展。  
但是TCP协议的势力过于强大，很多网络设备甚至对于UDP数据包做了很多不友好的策略，进行拦截从而导致成功连接率下降。  
主导者谷歌在自家产品做了很多尝试，国内腾讯公司也做了很多关于QUIC协议的尝试。  
其中腾讯云对QUIC协议表现了很大的兴趣，并做了一些优化然后在一些重点产品中对连接迁移、QUIC成功率、弱网环境耗时等进行了实验，给出了来自生产环境的诸多宝贵数据。  
简单看一组腾讯云在移动互联网场景下的不同丢包率下的请求耗时分布：  
![](http://brandonliu.pub/icon_blog_diu_bao.png)  
![](http://brandonliu.pub/icon_blog_diubao_table.png)  



#### HTTPS版本篇



#### 要点  


* HTTPS 是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。  
* HTTPS协议的主要作用是：建立一个信息安全通道，来确保数组的传输，确保网站的真实性。   
* HTTPS的SSL加密是在传输层实现的。  



#### 握手流程图：  


![](http://brandonliu.pub/icon_blog_woshou_http.jpeg) 



#### 工作原理  

* 客户端-->服务器 发起请求  

```
1.客户端发起请求到服务器。主要参数是支持的协议版本，加密方法以及一个随机数n1。

``` 

* 服务器-->客户端 发送证书，客户端验证证书。  

```
1.服务器收到请求并确认加密方法，然后返回公钥，以及一个由服务器生成的随机数n2;在这个阶段iOS中的CA认证的认证的证书会自动验证，而私有的证书则需要手动验证放行，否则拒绝链接

```

* 客户端-->服务器 发送消息  


```
1.客户端验证证书成功后会生成第三个随机数n3，并用第2步服务器返回的证书对该随机数加密，并发送给服务器，同时也会发送一些其他信息，比如：编码信息和客户端握手结束的通知。

````


* 服务器-->客户端 发送信息  

```
服务器用私钥解密后，得到客户端传来的第三个随机数n3,两端使用这三个随机数n1、n2、n3来生成Session Key。服务器向客户端发送编码信息和服务器握手结束通知。

```

* 完整性验证  


```
完整性验证以后，后面的信息传输就靠这个Session key进行对称加密了。  

```



#### SSL在握手的过程中主要交换了以下三个信息：  


* 加密通信协议：就是双方商量使用哪一种加密方式，假如两者支持的加密方式不匹配，则无法进行通信。  
* 数字证书：该证书包含了公钥等信息，一般是由服务器发给客户端，接收方通过验证这个证书是不是由信赖的CA签发，或者与本地的证书相对比，来判断证书是否可信；假如需要双向验证，则服务器和客户端都需要发送数字证书给对方验证。  
* 三个随机数n1,n2,n3:这三个随机数构成了后续通信过程中用来对数据进行对称加密解密的对话密钥。  



#### 优点  


* 使用HTTPS协议可认证用户和服务器，确保数据发送到正确的客户机和服务器。  
* HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比HTTP协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性。  
* HTTPS是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。  




#### 缺点  


* HTTPS握手阶段比较费时，会使页面加载时间延长50%，增加10%-20%的耗电。  
* HTTPS缓存不如HTTP高效，会增加数据开销。  
* SSL证书也需要钱，功能越强大的证书费用越高。  
* SSL证书需要绑定IP，不能再同一个IP上绑定多个域名，IPV4资源支持不了这种消耗。  



#### SSL/TLS协议介绍  

互联网的通信安全是建立在SSL/TLS协议之上。不使用SSL/TLS的HTTP协议，就是不加密的通信；会带来三大风险：  

* 窃听风险：第三方可以获取通信内容。—（截取银行卡、各种密码、手机号等）  
* 篡改风险：第三方可以修改通信内容。 —（劫持插入广告）  
* 冒失风险：第三方可以冒充他人身份参与通信。—（遭遇伪装服务器通信）  



#### SSL/TLS就是为了解决这三大风险而设计的，希望达到：  

* 所有信息都是加密传播，第三方无法窃听。  
* 具有校验机制，一旦被篡改，通信双方立即发现。  
* 配备身份证书，防止身份被冒充。  



#### SSL/TLS协议的基本思路  


* 公钥加密法：即客户端先向服务端索要公钥，然后用公钥加密信息，客户端收到密文后，用自己的私钥解密。  


#### 如何保证公钥不被篡改？  


* 解决方法：将公钥放在数字证书中。只要证书是可信的，公钥就是可信的。  


#### 公钥加密计算量太大，如何减少耗用的时间？  


* 解决方法：每一次对话（SESSION），客户端和服务器端都生成一个"对话密钥"（SESSION KEY），用它来加密信息。由于"对话密钥"是对称加密，所以运算速度非常快，而服务器公钥只用于加密"对话密钥"本身，这样就减少了加密运算的消耗时间。  

#### HTTPS协议耗时原因？  

* HTTP耗时 = TCP握手；HTTPS耗时 = TCP握手 + SSL握手 所以，HTTPS肯定比HTTP耗时，这就叫SSL延迟  


#### 中间人攻击  


中间人攻击是通过与客户端、服务器分别建立连接，来获得了明文的信息攻击方式。在这个过程中，客户端与服务器的通信被第三方解密、查看、修改。  


#### 原理图：  


![](http://brandonliu.pub/icon_blog_gongji_http.jpeg)



#### 为什么有些APP即便使用了HTTPS，还是会被中间人攻击呢？  


基本都是因为没做客户端验证，特别是在使用未经CA认证的证书时，更容易中招。关于黑客是如何在协议握手初期劫持服务，从而实现中间人攻击，可以做如下推演:  

* 黑客劫持到服务器公钥，并冒充客户端与服务器连接。  
* 黑客自己生成公钥，冒充服务器公钥返回给真正的客户端。  


如果客户端未做验证的话，就不会发现证书被替换，于是客户端会用黑客的公钥发送数据，黑客劫持数据后，用自己的私钥解密。   



#### 如何防止中间人攻击？  


* 把证书打包进APP，然后与服务器返回的证书对比验证，验证成功以后才允许连接。当然是用这种方式会导致一些问题，比如：当证书过期时APP连不上服务器，这时需要我们将新证书提前打包进APP。  
* 通过Socket通道从服务器传送证书进APP中，来实现无缝对接。






















